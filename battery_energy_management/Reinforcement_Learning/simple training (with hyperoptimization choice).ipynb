{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Package installation + importing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (1.12.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (1.0.3)\n",
      "Requirement already satisfied: virtualenv in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (20.14.1)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.16; python_version < \"3.9\" in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from ray) (1.19.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (3.6.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (3.20.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (6.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (4.4.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (8.1.2)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (1.2.0)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from ray) (1.34.1)\n",
      "Requirement already satisfied: requests in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (2.27.1)\n",
      "Requirement already satisfied: attrs in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray) (21.4.0)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from virtualenv->ray) (1.15.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv->ray) (2.5.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv->ray) (0.3.4)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from jsonschema->ray) (5.7.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from jsonschema->ray) (0.18.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from click>=7.0->ray) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray) (3.3)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema->ray) (3.8.0)\n",
      "Requirement already satisfied: ray[rllib] in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (3.20.0)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (2.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (3.6.0)\n",
      "Requirement already satisfied: virtualenv in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (20.14.1)\n",
      "Requirement already satisfied: numpy>=1.16; python_version < \"3.9\" in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from ray[rllib]) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (6.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (4.4.0)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (1.2.0)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from ray[rllib]) (1.34.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (8.1.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (1.0.3)\n",
      "Requirement already satisfied: attrs in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (21.4.0)\n",
      "Requirement already satisfied: matplotlib!=3.4.3; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (3.5.1)\n",
      "Requirement already satisfied: scikit-image; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (0.19.2)\n",
      "Requirement already satisfied: lz4; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (4.0.0)\n",
      "Requirement already satisfied: dm-tree; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (0.1.7)\n",
      "Requirement already satisfied: tensorboardX>=1.9; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (2.5)\n",
      "Requirement already satisfied: scipy; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (1.8.0)\n",
      "Requirement already satisfied: gym<0.22; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (0.21.0)\n",
      "Requirement already satisfied: pandas; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (1.4.2)\n",
      "Requirement already satisfied: tabulate; extra == \"rllib\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[rllib]) (0.8.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[rllib]) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[rllib]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[rllib]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[rllib]) (2.0.12)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from virtualenv->ray[rllib]) (1.15.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv->ray[rllib]) (0.3.4)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv->ray[rllib]) (2.5.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from jsonschema->ray[rllib]) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from jsonschema->ray[rllib]) (5.7.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from click>=7.0->ray[rllib]) (0.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (4.32.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (9.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.4.3; extra == \"rllib\"->ray[rllib]) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image; extra == \"rllib\"->ray[rllib]) (2.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image; extra == \"rllib\"->ray[rllib]) (2022.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image; extra == \"rllib\"->ray[rllib]) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image; extra == \"rllib\"->ray[rllib]) (2.16.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from gym<0.22; extra == \"rllib\"->ray[rllib]) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from pandas; extra == \"rllib\"->ray[rllib]) (2022.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema->ray[rllib]) (3.8.0)\n",
      "Requirement already satisfied: ray[tune] in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (1.12.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (4.4.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (1.0.3)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (3.20.0)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.16; python_version < \"3.9\" in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from ray[tune]) (1.19.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (3.6.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (8.1.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (2.27.1)\n",
      "Requirement already satisfied: attrs in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (21.4.0)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (1.2.0)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from ray[tune]) (1.34.1)\n",
      "Requirement already satisfied: virtualenv in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (20.14.1)\n",
      "Requirement already satisfied: pandas; extra == \"tune\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (1.4.2)\n",
      "Requirement already satisfied: tabulate; extra == \"tune\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (0.8.9)\n",
      "Requirement already satisfied: tensorboardX>=1.9; extra == \"tune\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from ray[tune]) (2.5)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from jsonschema->ray[tune]) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from jsonschema->ray[tune]) (5.7.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from click>=7.0->ray[tune]) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[tune]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[tune]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[tune]) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests->ray[tune]) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5.2 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv->ray[tune]) (0.3.4)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from virtualenv->ray[tune]) (2.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from pandas; extra == \"tune\"->ray[tune]) (2022.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema->ray[tune]) (3.8.0)\n",
      "Requirement already satisfied: tensorflow in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.30.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.5->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: tensorboard in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (50.3.1.post20201107)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (1.19.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard) (3.20.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (1.34.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (1.30.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from tensorboard) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard) (2.27.1)\n",
      "Requirement already satisfied: six in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
      "Requirement already up-to-date: hyperopt in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: numpy in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from hyperopt) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: future in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.2 in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: six in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: py4j in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from hyperopt) (0.10.9.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in d:\\pycharm 2020.3.3\\anaconda\\lib\\site-packages (from hyperopt) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\adm.000\\appdata\\roaming\\python\\python38\\site-packages (from hyperopt) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray\n",
    "\n",
    "!pip install \"ray[rllib]\"\n",
    "\n",
    "!pip install \"ray[tune]\"\n",
    "\n",
    "!pip install tensorflow\n",
    "!pip install tensorboard\n",
    "\n",
    "!pip install -U hyperopt\n",
    "\n",
    "!pip install --upgrade aiohttp\n",
    "\n",
    "import psutil\n",
    "import ray\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "house_id = 32\n",
    "data_dir = 'D:/Jupyter/data/train/'\n",
    "\n",
    "data_by = 'days' # 'days', 'periods'\n",
    "data_with_forecast = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns:\n",
    "\n",
    "data_by_periods (no forecast)\n",
    "- idx | timestamp | actual_load | actual_pv | price_buy_00 | price_sell_00\n",
    "\n",
    "data_by_periods (with forecast) \n",
    "- idx | timestamp | actual_load | actual_pv | load_00 | ... | pv_95 | price_buy_00 | ... | price_sell_95\n",
    "    - actual_load and actual_pv - are for current step (with shift '-1') - with consideration of last step\n",
    "\n",
    "data_by_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
    "import ray.rllib.agents.pg as pg\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "import numpy as np\n",
    "\n",
    "mode = 'train' # 'submit'\n",
    "additions = 0  # additions [0 - no forecast, 1 - with forecast]\n",
    "\n",
    "def get_data(mode, additions):    \n",
    "    train_data_not_normalized = pd.read_csv(f'{TRAIN_DATA_DIR}/{house_id}.csv', parse_dates=['timestamp'], sep=\";\")\n",
    "    train_data = train_data_not_normalized.copy()\n",
    "    train_data = train_data[~train_data.isnull()]\n",
    "    if additions == 0:\n",
    "        train_data = pd.concat([train_data.iloc[:, :5].copy(), train_data['price_buy_00'], train_data['price_sell_00']], axis=1)\n",
    "    else:\n",
    "        train_data = pd.concat([train_data.iloc[:, :10].copy(), train_data.iloc[:, 101:106].copy(), train_data['price_buy_00'], train_data['price_sell_00']], axis=1)\n",
    "    train_data_by_periods = [train_data[train_data['period_id'] == i] for i in np.sort(train_data['period_id'].unique())]\n",
    "    for i in range(len(train_data_by_periods)):\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].drop(columns = 'site_id',axis=1)\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].drop(columns = 'period_id',axis=1)\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].sort_values(by = 'timestamp')\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].reset_index()\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].drop(columns = 'index', axis=1)\n",
    "    if additions:\n",
    "        for period in range(len(train_data_by_periods)):\n",
    "            train_data_by_periods[period] = train_data_by_periods[period].drop(train_data_by_periods[period].index[(len(train_data_by_periods[period])-95) : len(train_data_by_periods[period])])\n",
    "    train_data_by_days = []\n",
    "    for i in range(len(train_data_by_periods)):\n",
    "        j = 0\n",
    "        while (j+1)*96 + 1 <= len(train_data_by_periods[i]):\n",
    "            train_data_by_days.append(train_data_by_periods[i][j*96:(j+1)*96 + 1])\n",
    "            j += 1\n",
    "    for i in range(len(train_data_by_days)):\n",
    "        train_data_by_days[i] = train_data_by_days[i].reset_index()\n",
    "        train_data_by_days[i] = train_data_by_days[i].drop(columns = 'index')\n",
    "    return train_data_by_days\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Environment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BatteryEnvTrain(gym.Env):\n",
    "\n",
    "    def __init__(self, df, timestep_idx = 0, power = 0, capacity = 0, efficiency = 0):\n",
    "\n",
    "        metadata = pd.read_csv(f'metadata.csv', index_col=0, sep=\";\").loc[house_id]\n",
    "        self.capacity = np.float32(metadata.Battery_1_Capacity * 1000)\n",
    "        self.power = np.float32(metadata.Battery_1_Power * 1000)\n",
    "        self.efficiency = np.float32(metadata.Battery_1_Charge_Efficiency)\n",
    "        \n",
    "        self.timestep_idx = timestep_idx    # id of a line\n",
    "        self.days_step = 0               # day for df\n",
    "        self.df_days = df                # df of a period\n",
    "\n",
    "        # Certain df (with properties of metadata)\n",
    "        self.df = self.df_days[self.days_step]\n",
    "        self.current_charge = INITIAL_CHARGE\n",
    "\n",
    "        # Action_Space.shape = number of batteries (=1)\n",
    "        self.action_space = spaces.Box(low = -1, high = 1, shape = (1,)) \n",
    "\n",
    "        # Observation_Space.shape = S_t x S_c x S_x (2 + 1 + (7 - 1) = 9)\n",
    "        # из df убираем 1 (timestamp)\n",
    "        observation_space_shape = (len(self.df.columns) - 1) + 2 + 1\n",
    "        #self.observation_space = spaces.Box(low=0, high=np.inf, shape = (observation_space_shape,))\n",
    "        #self.observation_space = spaces.Box(low = 0 - np.around((((self.power / self.capacity) * (15. / 60.)) * self.capacity) * (1. / self.efficiency)), high=np.inf, shape = (observation_space_shape,))\n",
    "        self.observation_space = spaces.Box(low = -np.inf, high=np.inf, shape = (observation_space_shape,))\n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.timestep_idx,:]\n",
    "        self.actual_pv = self.df.loc[self.timestep_idx + 1,:].actual_pv\n",
    "        self.actual_consumption = self.df.loc[self.timestep_idx + 1,:].actual_consumption\n",
    "\n",
    "        # initialize STATE = S_x x S_t x S_c\n",
    "        # S_x = price_buy_00 + price_sell_00 + actual_load + actual_pv + load_00 + pv_00\n",
    "        # S_t = week_day + day_quarter\n",
    "        # S_c = current_charge\n",
    "        # data[1] убирает timestamp из массива \n",
    "        tmp = self.data[1:].tolist()\n",
    "        self.state = [float(tmp[i]) for i in range(len(tmp))] + \\\n",
    "              [self.data.timestamp.weekday(), self.data.timestamp.quarter] + \\\n",
    "              [float(INITIAL_CHARGE)]\n",
    "        \n",
    "        # initialize REWARD and Rewards_memory (for graphics)\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.scores_memory = []\n",
    "        self.agent_outside_capacity_memory = []\n",
    "\n",
    "        # self.done (end of the episode = end of file)\n",
    "        self.terminal = False \n",
    "\n",
    "        # counter of going outside the capacity\n",
    "        self.checker_agent_outside_capacity = 0\n",
    "        \n",
    "        self.money_spent_cumulative = 0\n",
    "        self.money_spent_without_battery_cumulative = 0\n",
    "\n",
    "        self.money_spent_cumulative_episode = 0\n",
    "        self.money_spent_without_battery_cumulative_episode = 0\n",
    "\n",
    "        self.remember_step = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        action = (action * ((self.power / self.capacity) * (15. / 60.))) * self.capacity\n",
    "        self.current_charge = np.clip(self.current_charge, 0.0, self.capacity)\n",
    "        current_charge_old = self.current_charge\n",
    "\n",
    "        if action >= 0:\n",
    "            proposed_energy = current_charge_old + action * self.efficiency\n",
    "        else:\n",
    "            proposed_energy = current_charge_old + action * (1. / self.efficiency)\n",
    "        \n",
    "        actual_delta_charge_energy = proposed_energy - current_charge_old\n",
    "        net_energy = (actual_delta_charge_energy + self.actual_consumption) - self.actual_pv\n",
    "        self.current_charge = current_charge_old + actual_delta_charge_energy\n",
    "\n",
    "        price_buy = self.data.price_buy_00\n",
    "        price_sell = self.data.price_sell_00\n",
    "        price = price_buy if net_energy >= 0 else price_sell\n",
    "\n",
    "        grid_energy_without_battery = self.actual_consumption - self.actual_pv\n",
    "        price_without_battery = price_buy if grid_energy_without_battery >= 0 else price_sell\n",
    "\n",
    "        money_spent_without_battery = grid_energy_without_battery * (price_without_battery / 1000.)\n",
    "        money_spent = net_energy * (price / 1000.) \n",
    "\n",
    "        self.money_spent_cumulative += money_spent \n",
    "        self.money_spent_without_battery_cumulative += money_spent_without_battery\n",
    "\n",
    "        self.money_spent_cumulative_episode += money_spent\n",
    "        self.money_spent_without_battery_cumulative_episode += money_spent_without_battery\n",
    "\n",
    "        if self.current_charge <= self.capacity and self.current_charge >= 0:\n",
    "            self.reward = (self.timestep_idx + 1)/(self.remember_step + (self.timestep_idx + 1)) \n",
    "        else:\n",
    "            self.checker_agent_outside_capacity += 1        # 0 reward, checker > 0 -> reward for 'step' became lower\n",
    "            self.reward = 0\n",
    "            self.remember_step = self.timestep_idx\n",
    "\n",
    "        self.timestep_idx += 1\n",
    "        self.data = self.df.loc[self.timestep_idx,:]\n",
    "        self.actual_pv = self.df.loc[self.timestep_idx + 1,:].actual_pv\n",
    "        self.actual_consumption = self.df.loc[self.timestep_idx + 1,:].actual_consumption\n",
    "\n",
    "        tmp = self.data[1:].tolist()\n",
    "        self.state = [float(tmp[i]) for i in range(len(tmp))] + \\\n",
    "              [self.data.timestamp.weekday(), self.data.timestamp.quarter] + \\\n",
    "              [float(self.current_charge)]\n",
    "\n",
    "        self.terminal = (self.timestep_idx >= (len(self.df.index.unique()) - 2))\n",
    "        \n",
    "        if self.terminal:\n",
    "            #print('day number = ', self.days_step, \" / \", (len(self.df_days) - 1))\n",
    "            #print(\"days_step: \", self.days_step, \" / \", (len(train_data_by_days) - 1))\n",
    "            if psutil.virtual_memory().percent >= 80.0:\n",
    "                gc.collect()\n",
    "\n",
    "            self.agent_outside_capacity_memory.append(self.checker_agent_outside_capacity)\n",
    "            \n",
    "            if (self.days_step != (len(self.df_days) - 1)):\n",
    "                score = (self.money_spent_cumulative_episode - self.money_spent_without_battery_cumulative_episode)/np.abs(self.money_spent_without_battery_cumulative_episode)\n",
    "                self.reward += int(score < 0) * (-score) * 100 / ( 1 + self.checker_agent_outside_capacity)\n",
    "            else:\n",
    "                score = (self.money_spent_cumulative - self.money_spent_without_battery_cumulative)/np.abs(self.money_spent_without_battery_cumulative)\n",
    "                self.reward += int(score < 0) * (-score) * 10000 / ( 1 + self.checker_agent_outside_capacity)\n",
    "               \n",
    "            if self.days_step == (len(self.df_days) - 1):\n",
    "                \n",
    "                print('site id score average = ', (self.money_spent_cumulative - self.money_spent_without_battery_cumulative)/np.abs(self.money_spent_without_battery_cumulative))\n",
    "                print('agent outside capacity average = ', np.sum(self.agent_outside_capacity_memory), \"out of \", len(self.df_days[0]) * len(self.df_days))\n",
    "                self.scores_memory.clear()\n",
    "                self.agent_outside_capacity_memory.clear()\n",
    "                self.days_step = 0\n",
    "\n",
    "                self.money_spent_cumulative = 0\n",
    "                self.money_spent_without_battery_cumulative = 0\n",
    "                self.money_spent_cumulative_episode = 0\n",
    "                self.money_spent_without_battery_cumulative_episode = 0\n",
    "\n",
    "                self.checker_agent_outside_capacity = 0\n",
    "                self.remember_step = 0\n",
    "\n",
    "                self.current_charge = INITIAL_CHARGE\n",
    "            else:\n",
    "                self.days_step += 1\n",
    "                self.money_spent_cumulative_episode = 0\n",
    "                self.money_spent_without_battery_cumulative_episode = 0\n",
    "                self.checker_agent_outside_capacity = 0\n",
    "                self.remember_step = 0\n",
    "\n",
    "            return self.state, float(self.reward), self.terminal, {}\n",
    "\n",
    "        return self.state, float(self.reward), self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.df = self.df_days[self.days_step]\n",
    "\n",
    "        # reseting df\n",
    "        self.timestep_idx = 0\n",
    "        self.data = self.df.loc[self.timestep_idx,:]\n",
    "        self.actual_pv = self.df.loc[self.timestep_idx + 1,:].actual_pv\n",
    "        self.actual_consumption = self.df.loc[self.timestep_idx + 1,:].actual_consumption\n",
    "\n",
    "        # initialize state\n",
    "        tmp = self.data[1:].tolist()\n",
    "        self.state = [float(tmp[i]) for i in range(len(tmp))] + \\\n",
    "              [self.data.timestamp.weekday(), self.data.timestamp.quarter] + \\\n",
    "              [float(self.current_charge)]\n",
    "\n",
    "        # reset done, memory, current_charge, reward\n",
    "        self.terminal = False \n",
    "        self.reward = 0\n",
    "\n",
    "        #return self.state\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Ray RLlib training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ------- ENV CREATION\n",
    "house_id = 32\n",
    "INITIAL_CHARGE = 0.0\n",
    "MODE = 'submit'\n",
    "data_dir = ''\n",
    "METADATA_DIR = data_dir\n",
    "TRAIN_DATA_DIR = data_dir\n",
    "\n",
    "def env_creator(_):\n",
    "    data_by_days = get_data(MODE, 0)\n",
    "    return BatteryEnvTrain(data_by_days.copy(), 0)\n",
    "\n",
    "env_name = 'BatteryEnvTrain-v0'\n",
    "\n",
    "# env-name should be according to this: [someting]-v[something]     example: battery-v0\n",
    "register_env(env_name, env_creator)\n",
    "\n",
    "# allowing 2 gpus\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training (no hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Algorithms test on MountainCarContinuous-v0 (continuous action space)\n",
    "# [working with init() - BC, {DDPG, TD3}, MARWIL, PG, SAC]\n",
    "# [working with initi(cpus) - {A2C, A3C} (3), ARS (6), ES (11), APEX_DDPG (?), IMPALA(2 gpu), {PPO, APPO} (3)]\n",
    "# [Discrete action-space - {DQN, Rainbow}, APEX_DQN, R2D2, SlateQ, {LinUCB, LinTS}, AlphaZero]\n",
    "# [Different - Dreamer(images only)]\n",
    "\n",
    "# ERROR:\n",
    "# CQL on MountainCarContinuous-v0 - `ReplayBuffer(size)` has been deprecated. Use `ReplayBuffer(capacity)` instead. This will raise an error in the future\n",
    "#                                    `execution_plan` functions should accept `trainer`, `workers`, and `config` as args!\n",
    "# MAML (3) on MountainCarContinuous-v0 - execution_plan() takes 2 positional arguments but 3 were given\n",
    "#                                         'Continuous_MountainCarEnv' object has no attribute 'sample_tasks'\n",
    "# MBMPO (?) on MountainCarContinuous-v0 - env doest not have a `reward()` method, needed for MB-MPO!\n",
    "\n",
    "# Careful:\n",
    "# if env is scuffed -> ray.shutdown() -> re-register env -> execute again\n",
    "\n",
    "#----------------------------\n",
    "# DDPG gives accurate results\n",
    "# PPO gives weird results (from -100 to 100 sometimes but in converge to same as DDPG)\n",
    "#----------------------------\n",
    "\n",
    "\n",
    "ray.init(num_cpus=12, num_gpus=1, ignore_reinit_error=True)\n",
    "analysis = tune.run(\n",
    "              \"PPO\",\n",
    "              stop={\"timesteps_total\": 10500000},\n",
    "              name='Battery_experiment',\n",
    "              #verbose=True,                                               # helps with clearing outputs, but not enough info (not very useful)\n",
    "              #metric=\"task_score\",\n",
    "              mode=\"max\",\n",
    "              config={      # https://docs.ray.io/en/latest/rllib/rllib-training.html#common-parameters\n",
    "                  \"env\": env_name,\n",
    "                  #\"num_workers\": 2,                                      # sum problems with those 2 for some reason\n",
    "                  #\"num_gpus\": 2,                                         #\n",
    "                  #\"sgd_minibatch_size\": tune.choice([128, 512, 2048]),   # doesnt understands what is it\n",
    "                  #\"train_batch_size\": tune.choice([int(len(train_data_by_periods[0])/2),len(train_data_by_periods[0]), len(train_data_by_periods[0])*2, len(train_data_by_periods[0])*10]),  # for each one 'll start training again\n",
    "                  'vf_clip_param': math.inf,\n",
    "                  \"framework\": \"tf2\",\n",
    "                  \"eager_tracing\": True,\n",
    "                  \"lr\": tune.grid_search([1e-3, 1e-4, 1e-5]),\n",
    "                  #\"sgd_minibatch_size\": len(train_data_by_periods[0]),\n",
    "                  #\"train_batch_size\": len(train_data_by_periods[0])*len(train_data_by_periods)*3,\n",
    "                  #\"evaluation_interval\": 1,\n",
    "                  #\"evaluation_duration\": 2,\n",
    "                  #\"evaluation_duration_unit\": \"episodes\",\n",
    "\n",
    "                  #\"explore\": True,\n",
    "                  #\"exploration_config\": {\n",
    "                  #  \"type\": \"StochasticSampling\",\n",
    "                  #  \"random_timesteps\": 0,\n",
    "                  #},\n",
    "\n",
    "              },\n",
    "              #restore='/content/root/ray_results/Battery_experiment/DDPG_BatteryEnvTrain-v0_560eb_00001_1_2021-11-23_16-56-51/checkpoint_000300/checkpoint-300',\n",
    "              num_samples=1,\n",
    "              checkpoint_at_end=True,                                     # doesnt matter (even if stopped manually - creates checkpoint at the end)\n",
    "              #checkpoint_freq = 30000,\n",
    "          )\n",
    "\n",
    "#print(\"best hyperparameters: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training (hyperparameter optimization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from ray.rllib.agents.ddpg import DDPGTrainer\n",
    "from ray.rllib.rollout import rollout\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "def on_train_result(info):\n",
    "    info[\"result\"][\"objective\"] = info[\"result\"][\"episode_reward_mean\"]\n",
    "\n",
    "def get_best_trials(trials, metric):\n",
    "    return sorted(trials, key=lambda trial: trial.last_result[metric], reverse=True)\n",
    "\n",
    "def get_agent(trial):\n",
    "    agent = DDPGAgent(config=trial.config)\n",
    "    agent.restore(trial._checkpoint.value)\n",
    "    return agent\n",
    "\n",
    "def remove_checkpoints(trials):\n",
    "    for trial in trials:\n",
    "        for path in glob(os.path.join(trial._checkpoint.value + \"*\")):\n",
    "            os.remove(path)\n",
    "        os.rmdir(os.path.dirname(trial._checkpoint.value))\n",
    "        trial.clear_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'Population Based scheduler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "def explore(config):\n",
    "    # ensure we collect enough timesteps to do sgd\n",
    "    if config[\"train_batch_size\"] < config[\"sgd_minibatch_size\"] * 2:\n",
    "        config[\"train_batch_size\"] = config[\"sgd_minibatch_size\"] * 2\n",
    "    # ensure we run at least one sgd iter\n",
    "    if config[\"num_sgd_iter\"] < 1:\n",
    "        config[\"num_sgd_iter\"] = 1\n",
    "    return config\n",
    "\n",
    "pbt = PopulationBasedTraining(\n",
    "    time_attr=\"time_total_s\",\n",
    "    perturbation_interval=120,\n",
    "    resample_probability=0.25,\n",
    "    # Specifies the mutations of these hyperparams\n",
    "    hyperparam_mutations={\n",
    "        \"lambda\": lambda: random.uniform(0.9, 1.0),\n",
    "        \"clip_param\": lambda: random.uniform(0.01, 0.5),\n",
    "        \"lr\": [1e-3, 5e-4, 1e-4, 5e-5, 1e-5],\n",
    "        \"num_sgd_iter\": lambda: random.randint(1, 30),\n",
    "        \"sgd_minibatch_size\": lambda: random.randint(128, 16384),\n",
    "        \"train_batch_size\": lambda: random.randint(2000, 160000),\n",
    "    },\n",
    "    custom_explore_fn=explore)\n",
    "\n",
    "# custom parameters hyperoptimization - https://docs.ray.io/en/latest/tune/examples/ax_example.html\n",
    "# give an env config (from there take out needed values)\n",
    "\n",
    "ray.init(num_cpus=12, num_gpus=0)\n",
    "analysis = tune.run(\n",
    "              \"PPO\",\n",
    "              stop={\"timesteps_total\": 10500000},\n",
    "              name='Battery_experiment',\n",
    "              scheduler=pbt,\n",
    "              mode=\"max\",\n",
    "              config={                                                     # https://docs.ray.io/en/latest/rllib/rllib-training.html#common-parameters\n",
    "                  \"env\": env_name,\n",
    "                  #\"sgd_minibatch_size\": tune.choice([128, 512, 2048]),   # doesnt understands what is it\n",
    "                  #\"train_batch_size\": tune.choice([int(len(train_data_by_periods[0])/2),len(train_data_by_periods[0]), len(train_data_by_periods[0])*2, len(train_data_by_periods[0])*10]),  # for each one 'll start training again\n",
    "                  'vf_clip_param': math.inf,\n",
    "                  \"framework\": \"tf2\",\n",
    "                  \"eager_tracing\": True,\n",
    "                  \"lr\": 5e-6,\n",
    "              },\n",
    "              num_samples=15,\n",
    "              checkpoint_at_end=True,                                     # doesnt matter (even if stopped manually - creates checkpoint at the end)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'HyperBand' scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_part_of_df = len(train_data_by_periods[0]) - 2\n",
    "\n",
    "ray.init(num_cpus=12, num_gpus=1)\n",
    "\n",
    "hyperopt = HyperOptSearch({\n",
    "    #\"rollout_fragment_length\": hp.choice(\"rollout_fragment_length\", [256, 512]),\n",
    "    #\"entropy_coeff\": hp.choice(\"entropy_coeff\", [1e-2, 1e-3]),\n",
    "    #\"lambda\": hp.choice(\"lambda\", [1, 0.5]), # 1, 0.5\n",
    "    \"lr\": hp.choice(\"entropy_coeff\", [1e-5]),   # 1e-3, 1e-4\n",
    "    \"vf_loss_coeff\": hp.choice(\"vf_loss_coeff\", [0.5]),  # 0.5, 0.25\n",
    "    \"timesteps_per_iteration\": one_part_of_df\n",
    "    },\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "hyperband = AsyncHyperBandScheduler(            # better sort it when it started training (to get rid of failed explorations because otherwise it'll take 2 long to learn)\n",
    "time_attr=\"training_iteration\",\n",
    "metric=\"episode_reward_mean\",\n",
    "max_t=500,           # max time units per trial = TIMESTEPS OF TRAINING (3838 * max_t)\n",
    "mode=\"max\",\n",
    "grace_period=50,      # only stop trials at least this old in time [1 is because 1st output will be after exploration despite ts=3838]\n",
    ")\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "analysis = tune.run(\n",
    "              \"A3C\",\n",
    "              name=now,\n",
    "              num_samples=10,\n",
    "              #checkpoint_freq = one_part_of_df,        # helps to draw graphics of 'reward_mean_episode'\n",
    "              #search_alg=hyperopt,\n",
    "              #scheduler=hyperband,\n",
    "              stop={\"timesteps_total\": 10000000},\n",
    "              config={\n",
    "                  \"env\": env_name,\n",
    "                  \"callbacks\": {\"on_train_result\": tune.function(on_train_result)},\n",
    "              },\n",
    "              #checkpoint_at_end=True,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Iterative training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_id = 32\n",
    "INITIAL_CHARGE = 0.0\n",
    "MODE = 'train'\n",
    "METADATA_DIR = ''\n",
    "TRAIN_DATA_DIR = f'/{MODE}'\n",
    "\n",
    "def env_creator(_):\n",
    "    data_by_days = get_data(MODE, 0)\n",
    "    return BatteryEnvTrain(data_by_days.copy(), 0)\n",
    "\n",
    "env_name = 'BatteryEnvTrain-v0' \n",
    "register_env(env_name, env_creator)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "data_by_days = get_data(MODE, 0)\n",
    "length_timesteps = len(data_by_days)*len(data_by_days[0])\n",
    "number_of_episodes = len(data_by_days)\n",
    "\n",
    "hyperband = AsyncHyperBandScheduler(            # better sort it when it started training (to get rid of failed explorations because otherwise it'll take 2 long to learn)\n",
    "time_attr=\"episodes_total\",\n",
    "metric=\"episode_reward_mean\",         \n",
    "mode=\"max\",\n",
    "max_t= length_timesteps, \n",
    "grace_period = length_timesteps,\n",
    ")\n",
    "\n",
    "register_env(env_name, env_creator)\n",
    "ray.init(num_cpus=9, num_gpus=0)\n",
    "analysis = tune.run(\n",
    "              \"PPO\",\n",
    "              stop={\"training_iteration\": 10},\n",
    "              name='Battery_experiment',\n",
    "              #mode=\"max\",\n",
    "              #verbose=0,\n",
    "              #scheduler=hyperband,\n",
    "              config={      \n",
    "                  \"env\": env_name,\n",
    "                  \"framework\": \"tf2\",\n",
    "                  \"eager_tracing\": True,\n",
    "                  \"lr\": 5e-5,\n",
    "                  'vf_clip_param': math.inf,\n",
    "              },\n",
    "              num_samples=3,\n",
    "              checkpoint_at_end=True,                                     # doesnt matter (even if stopped manually - creates checkpoint at the end)\n",
    "              checkpoint_freq = 1000,                                  # 1 iter = 200 steps\n",
    "              #reuse_actors=True,\n",
    "          )\n",
    "\n",
    "trial_logdir = analysis.get_best_logdir(metric=\"episode_reward_mean\", mode=\"max\")  \n",
    "best_checkpoint = analysis.get_best_checkpoint(trial_logdir, metric=\"episode_reward_mean\", mode=\"max\")\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "number_of_iterations = 200\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    \n",
    "    #hyperband = AsyncHyperBandScheduler(            # better sort it when it started training (to get rid of failed explorations because otherwise it'll take 2 long to learn)\n",
    "    #time_attr=\"timesteps_total\",\n",
    "    #metric=\"episode_reward_mean\",         \n",
    "    #mode=\"max\",\n",
    "    #max_t= (length_timesteps*3)*(i+2), \n",
    "    #grace_period = length_timesteps + (length_timesteps*3)*(i+1)\n",
    "    #)\n",
    "    \n",
    "    for j in range(5): print('----------')\n",
    "    print(f'starts loop {i + 2} / {number_of_iterations} ')\n",
    "    for j in range(5): print('----------')\n",
    "\n",
    "    register_env(env_name, env_creator)\n",
    "    ray.init(num_cpus=9, num_gpus=0)\n",
    "    analysis = tune.run(\n",
    "                  \"PPO\",\n",
    "                  stop={\"training_iteration\": 10 * (i + 2)},\n",
    "                  name='Battery_experiment',\n",
    "                  #mode=\"max\",\n",
    "                  #verbose=0,\n",
    "                  #scheduler=hyperband,\n",
    "                  config={      \n",
    "                      \"env\": env_name,\n",
    "                      \"framework\": \"tf2\",\n",
    "                      \"eager_tracing\": True,\n",
    "                      \"lr\": 5e-5,\n",
    "                      'vf_clip_param': math.inf,\n",
    "                  },\n",
    "                  restore=best_checkpoint,\n",
    "                  num_samples=3,\n",
    "                  checkpoint_at_end=True,                                     # doesnt matter (even if stopped manually - creates checkpoint at the end)\n",
    "                  checkpoint_freq = 1000,                                  # 1 iter = 200 steps\n",
    "                  #reuse_actors=True,\n",
    "              )\n",
    "\n",
    "    trial_logdir = analysis.get_best_logdir(metric=\"episode_reward_mean\", mode=\"max\")  \n",
    "    best_checkpoint = analysis.get_best_checkpoint(trial_logdir, metric=\"episode_reward_mean\", mode=\"max\")\n",
    "    \n",
    "    ray.shutdown()\n",
    "\n",
    "from pathlib import Path\n",
    "f = str(best_checkpoint)\n",
    "p = str(Path(f).parents[1])\n",
    "!zip -r /home/notebooks/Battery_experiment_best.zip {p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 200\n",
    "stopped_iteration = 550\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    \n",
    "    hyperband = AsyncHyperBandScheduler(            # better sort it when it started training (to get rid of failed explorations because otherwise it'll take 2 long to learn)\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"episode_reward_mean\",         \n",
    "    mode=\"max\",\n",
    "    max_t= stopped_iteration + 5*(i+1), \n",
    "    grace_period = stopped_iteration + 5*(i)\n",
    "    )\n",
    "    \n",
    "    for j in range(5): print('----------')\n",
    "    print(f'{i + 2} / {number_of_iterations}  loops')\n",
    "    print(f'{(i + 2)*5} / {number_of_iterations * 5} iterations')\n",
    "    for j in range(5): print('----------')\n",
    "\n",
    "    register_env(env_name, env_creator)\n",
    "    \n",
    "    ray.init(num_cpus=9, num_gpus=0)\n",
    "\n",
    "    analysis = tune.run(\n",
    "                  \"PPO\",\n",
    "                  stop={\"training_iteration\": stopped_iteration + 10 * (i + 1)},\n",
    "                  name='Battery_experiment',\n",
    "                  #mode=\"max\",\n",
    "                  #verbose=0,\n",
    "                  #scheduler=hyperband,\n",
    "                  config={      \n",
    "                      \"env\": env_name,\n",
    "                      \"framework\": \"tf2\",\n",
    "                      \"eager_tracing\": True,\n",
    "                      \"lr\": 5e-5,\n",
    "                      'vf_clip_param': math.inf,\n",
    "                  },\n",
    "                  restore=best_checkpoint,\n",
    "                  num_samples=3,\n",
    "                  checkpoint_at_end=True,                                     # doesnt matter (even if stopped manually - creates checkpoint at the end)\n",
    "                  checkpoint_freq = 1000,                                  # 1 iter = 200 steps\n",
    "                  #reuse_actors=True,\n",
    "              )\n",
    "\n",
    "    trial_logdir = analysis.get_best_logdir(metric=\"episode_reward_mean\", mode=\"max\")  \n",
    "    best_checkpoint = analysis.get_best_checkpoint(trial_logdir, metric=\"episode_reward_mean\", mode=\"max\")\n",
    "    \n",
    "    ray.shutdown()\n",
    "\n",
    "from pathlib import Path\n",
    "f = str(best_checkpoint)\n",
    "p = str(Path(f).parents[1])\n",
    "!zip -r /home/notebooks/Battery_experiment_best.zip {p}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Some Training helping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PERFECT CONFIG SO FAR\n",
    "\n",
    "hyperopt = HyperOptSearch({\n",
    "    #\"twin_q\": hp.choice(\"twin_q\", [False, True]),\n",
    "    #\"critic_lr\": hp.choice(\"critic_lr\", [1e-3, 1e-4]),\n",
    "    #\"actor_lr\": hp.choice(\"actor_lr\", [1e-3, 1e-4]),\n",
    "    \"train_batch_size\": 256),        # by paralleling 1x time for 256, 2x for 512, 4x for 1024 (paralleling helps to train every sample at the same time) [take 256 to make it faster]\n",
    "    \"learning_starts\": one_part_of_df * 2,        # per train session (meaning 1 time, not per episode) - x2 seems better\n",
    "    \"timesteps_per_iteration\": one_part_of_df,\n",
    "    #\"actor_hidden_activation\": hp.choice(\"actor_hidden_activation\", [\"relu\", \"tanh\"]),      # idk whats better (leave 'relu' cuz of ray developers)\n",
    "    #\"critic_hidden_activation\": hp.choice(\"critic_hidden_activation\", [\"relu\", \"tanh\"]),\n",
    "    },\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "\n",
    "hyperband = AsyncHyperBandScheduler(            # better sort it when it started training (to get rid of failed explorations because otherwise it'll take 2 long to learn)\n",
    "time_attr=\"training_iteration\",\n",
    "metric=\"episode_reward_mean\",\n",
    "max_t=1500000/one_part_of_df,           # max time units per trial = TIMESTEPS OF TRAINING (3838 * 5)\n",
    "mode=\"max\",\n",
    "grace_period=2,      # take something like 5-10% of timesteps {to let it train for a while and then delete}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "# 1) HyperOptSearch can't understand 'num_atoms', 'noisy', 'hiddens', \"objective\", 'max_concurrent\n",
    "#    Need to specify \"objective\" as \"reward_episode_mean\" and mode=\"max\"\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "#dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "ray.init(num_cpus=6, num_gpus=1)\n",
    "\n",
    "# HyperOptSearch(space, metric, max_concurrent)\n",
    "hyperopt = HyperOptSearch(\n",
    "    {\n",
    "        \"gamma\": (1 - hp.loguniform(\"_gamma\", np.log(1e-4), np.log(1e-1))) / 1,\n",
    "        \"lr\": hp.loguniform(\"lr\", np.log(1e-6), np.log(1e-3)),\n",
    "    },\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "'''\n",
    "hyperopt = HyperOptSearch(\n",
    "    {\n",
    "        \"gamma\": (1 - hp.loguniform(\"_gamma\", np.log(1e-4), np.log(1e-1))) / 1,\n",
    "        \"lr\": hp.loguniform(\"lr\", np.log(1e-6), np.log(1e-3)),\n",
    "\n",
    "        \"num_atoms\": hp.choice(\"num_atoms\", [1, 51]),\n",
    "        \"noisy\": hp.choice(\"noisy\", [False, True]),\n",
    "        \"hiddens\": hp.choice(\n",
    "            \"hiddens\",\n",
    "            [\n",
    "                [scope.int(64 * (2 ** hp.quniform(\"_layer_1_1\", 0, 3, 1)))],\n",
    "                [\n",
    "                    scope.int(64 * (2 ** hp.quniform(\"_layer_2_1\", 0, 3, 1))),\n",
    "                    scope.int(64 * (2 ** hp.quniform(\"_layer_2_2\", 0, 3, 1))),\n",
    "                ],\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "    metric=\"objective\",\n",
    "    mode=\"max\",\n",
    "    #max_concurrent=32,  # old (use tune.suggest.ConcurrencyLimiter() ???)\n",
    ")\n",
    "'''\n",
    "\n",
    "# Scheduler 'sorting' = deleting 'bad' trials (number of 'time' that trial lives = max_t  {because time_attr = 'training_iteration'})\n",
    "#\n",
    "hyperband = AsyncHyperBandScheduler(\n",
    "    time_attr=\"number_of_trials\", metric=\"episode_reward_mean\", mode=\"max\", max_t=20\n",
    ")\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "analysis = tune.run(\n",
    "              \"DDPG\",\n",
    "              name=now,\n",
    "              num_samples=2,\n",
    "              search_alg=hyperopt,\n",
    "              scheduler=hyperband,\n",
    "              stop={\"timesteps_total\": 300000},\n",
    "              config={\n",
    "                  \"env\": env_name,\n",
    "                  #\"num_gpus\": np.clip(num_gpus / num_cpus, 0, 1),\n",
    "                  \"callbacks\": {\"on_train_result\": tune.function(on_train_result)},\n",
    "              },\n",
    "              checkpoint_at_end=True,                                     # doesnt matter (even if stopped manually - creates checkpoint at the end)\n",
    "              #local_dir=os.path.join(dir_path, \"ray_results\"),\n",
    "          )\n",
    "\n",
    "\n",
    "best_trials = get_best_trials(trials, \"episode_reward_mean\")\n",
    "best_trial = best_trials[0]\n",
    "\n",
    "agent = get_agent(best_trial)\n",
    "\n",
    "print(\n",
    "    \"best score: {}, config: {}, checkpoint: {}\".format(\n",
    "        best_trial.last_result[\"episode_reward_mean\"],\n",
    "        best_trial.config,\n",
    "        best_trial._checkpoint.value,\n",
    "    )\n",
    ")\n",
    "\n",
    "remove_checkpoints(best_trials[1:])\n",
    "\n",
    "rollout(agent, env_id, 1000, no_render=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RF9fauWvIxFP"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
    "import ray.rllib.agents.pg as pg\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "import numpy as np\n",
    "\n",
    "def get_data(mode, additions):      # additions [0 - no forecast, 1 - with forecast]\n",
    "    train_data_not_normalized = pd.read_csv(f'{TRAIN_DATA_DIR}/{house_id}.csv', parse_dates=['timestamp'], sep=\";\")\n",
    "    train_data = train_data_not_normalized.copy()\n",
    "    train_data = train_data[~train_data.isnull()]\n",
    "    if additions == 0:\n",
    "        train_data = pd.concat([train_data.iloc[:, :5].copy(), train_data['price_buy_00'], train_data['price_sell_00']], axis=1)\n",
    "    else:\n",
    "        train_data = pd.concat([train_data.iloc[:, :10].copy(), train_data.iloc[:, 101:106].copy(), train_data['price_buy_00'], train_data['price_sell_00']], axis=1)\n",
    "    train_data_by_periods = [train_data[train_data['period_id'] == i] for i in np.sort(train_data['period_id'].unique())]\n",
    "    for i in range(len(train_data_by_periods)):\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].drop(columns = 'site_id')\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].drop(columns = 'period_id')\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].sort_values(by = 'timestamp')\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].reset_index()\n",
    "            train_data_by_periods[i] = train_data_by_periods[i].drop(columns = 'index')\n",
    "    if additions:\n",
    "        for period in range(len(train_data_by_periods)):\n",
    "            train_data_by_periods[period] = train_data_by_periods[period].drop(train_data_by_periods[period].index[(len(train_data_by_periods[period])-95) : len(train_data_by_periods[period])])\n",
    "    train_data_by_days = []\n",
    "    for i in range(len(train_data_by_periods)):\n",
    "        j = 0\n",
    "        while (j+1)*96 + 1 <= len(train_data_by_periods[i]):\n",
    "            train_data_by_days.append(train_data_by_periods[i][j*96:(j+1)*96 + 1])\n",
    "            j += 1\n",
    "    for i in range(len(train_data_by_days)):\n",
    "        train_data_by_days[i] = train_data_by_days[i].reset_index()\n",
    "        train_data_by_days[i] = train_data_by_days[i].drop(columns = 'index')\n",
    "    return train_data_by_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "q_CBBTRwJBM8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "house_id =  32\n",
      "mode =  submit\n",
      "algorithm =  ppo\n",
      "1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973486)\u001b[0m 2022-05-02 16:30:32,169\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973486)\u001b[0m 2022-05-02 16:30:32,169\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973486)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973486)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973484)\u001b[0m 2022-05-02 16:30:32,292\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973484)\u001b[0m 2022-05-02 16:30:32,292\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973484)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3973484)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2022-05-02 16:30:32,681\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n",
      "2022-05-02 16:30:32,697\tINFO trainable.py:534 -- Restored on 10.3.0.4 from checkpoint: /home/dinveel/ray_results/Battery_experiment/PPO_BatteryEnvTrain-v0_71bdb_00001_1_2022-05-02_16-18-14/checkpoint_000550/checkpoint-550\n",
      "2022-05-02 16:30:32,698\tINFO trainable.py:543 -- Current state after restoring: {'_iteration': 550, '_timesteps_total': 2200000, '_time_total': 6483.102120399475, '_episodes_total': 23100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974023)\u001b[0m 2022-05-02 16:30:45,816\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974023)\u001b[0m 2022-05-02 16:30:45,817\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974023)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974023)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974021)\u001b[0m 2022-05-02 16:30:45,947\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974021)\u001b[0m 2022-05-02 16:30:45,947\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974021)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974021)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2022-05-02 16:30:46,296\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n",
      "2022-05-02 16:30:46,318\tINFO trainable.py:534 -- Restored on 10.3.0.4 from checkpoint: /home/dinveel/ray_results/Battery_experiment/PPO_BatteryEnvTrain-v0_71bdb_00001_1_2022-05-02_16-18-14/checkpoint_000550/checkpoint-550\n",
      "2022-05-02 16:30:46,318\tINFO trainable.py:543 -- Current state after restoring: {'_iteration': 550, '_timesteps_total': 2200000, '_time_total': 6483.102120399475, '_episodes_total': 23100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974591)\u001b[0m 2022-05-02 16:30:59,243\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974591)\u001b[0m 2022-05-02 16:30:59,244\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974591)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974591)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974589)\u001b[0m 2022-05-02 16:30:59,261\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974589)\u001b[0m 2022-05-02 16:30:59,261\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974589)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3974589)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2022-05-02 16:30:59,665\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n",
      "2022-05-02 16:30:59,687\tINFO trainable.py:534 -- Restored on 10.3.0.4 from checkpoint: /home/dinveel/ray_results/Battery_experiment/PPO_BatteryEnvTrain-v0_71bdb_00001_1_2022-05-02_16-18-14/checkpoint_000550/checkpoint-550\n",
      "2022-05-02 16:30:59,687\tINFO trainable.py:543 -- Current state after restoring: {'_iteration': 550, '_timesteps_total': 2200000, '_time_total': 6483.102120399475, '_episodes_total': 23100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975179)\u001b[0m 2022-05-02 16:31:12,606\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975179)\u001b[0m 2022-05-02 16:31:12,606\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975179)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975179)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975178)\u001b[0m 2022-05-02 16:31:12,589\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975178)\u001b[0m 2022-05-02 16:31:12,589\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975178)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975178)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2022-05-02 16:31:12,959\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n",
      "2022-05-02 16:31:12,994\tINFO trainable.py:534 -- Restored on 10.3.0.4 from checkpoint: /home/dinveel/ray_results/Battery_experiment/PPO_BatteryEnvTrain-v0_71bdb_00001_1_2022-05-02_16-18-14/checkpoint_000550/checkpoint-550\n",
      "2022-05-02 16:31:12,995\tINFO trainable.py:543 -- Current state after restoring: {'_iteration': 550, '_timesteps_total': 2200000, '_time_total': 6483.102120399475, '_episodes_total': 23100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975751)\u001b[0m 2022-05-02 16:31:25,945\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975751)\u001b[0m 2022-05-02 16:31:25,945\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975751)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975751)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975754)\u001b[0m 2022-05-02 16:31:26,080\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975754)\u001b[0m 2022-05-02 16:31:26,080\tWARNING env.py:120 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975754)\u001b[0m /anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/gym/spaces/box.py:142: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3975754)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2022-05-02 16:31:26,307\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n",
      "2022-05-02 16:31:26,341\tINFO trainable.py:534 -- Restored on 10.3.0.4 from checkpoint: /home/dinveel/ray_results/Battery_experiment/PPO_BatteryEnvTrain-v0_71bdb_00001_1_2022-05-02_16-18-14/checkpoint_000550/checkpoint-550\n",
      "2022-05-02 16:31:26,342\tINFO trainable.py:543 -- Current state after restoring: {'_iteration': 550, '_timesteps_total': 2200000, '_time_total': 6483.102120399475, '_episodes_total': 23100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores average =  -0.05023388\n",
      "outside capacity average =  0.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = '/home/ray_results/Battery_experiment/PPO_BatteryEnvTrain-v0_44ee4_00000_0_2022-05-01_13-54-50/checkpoint_000500/checkpoint-500'\n",
    "checkpoint_path = best_checkpoint\n",
    "RL_algorithm = 'ppo'\n",
    "\n",
    "env_name = 'BatteryEnvTrain-v0' \n",
    "\n",
    "scores = []\n",
    "outside_capacity = []\n",
    "\n",
    "# calculating for different seeds\n",
    "rang = 5    \n",
    "\n",
    "print('------------')\n",
    "print('house_id = ', house_id)\n",
    "print('mode = ', MODE)\n",
    "print('algorithm = ', RL_algorithm) \n",
    "\n",
    "for i in range(rang):\n",
    "    print(i+1, f\"/ {rang}\")\n",
    "    env = env_creator(house_id)\n",
    "\n",
    "    if RL_algorithm == 'ppo':\n",
    "        config = ppo.DEFAULT_CONFIG.copy()\n",
    "        custom_config = {\"env\": env_name, 'vf_clip_param': math.inf, \"framework\": \"tf2\", \"eager_tracing\": True, \"lr\": 5e-5,}\n",
    "        for key in custom_config.keys():\n",
    "            config[key] = custom_config[key]\n",
    "        agent = ppo.PPOTrainer(config=config, env=env_name) \n",
    "    elif RL_algorithm == 'pg':\n",
    "        config = pg.DEFAULT_CONFIG.copy()\n",
    "        custom_config = {\"env\": env_name, \"framework\": \"tf2\", \"eager_tracing\": True, \"lr\": 5e-5,}\n",
    "        for key in custom_config.keys():\n",
    "            config[key] = custom_config[key]\n",
    "        agent = pg.PGTrainer(config=config, env=env_name) \n",
    "\n",
    "    agent.restore(checkpoint_path)                                  # restore agent's weights (that were made during training)\n",
    "    \n",
    "    # ------ LOOP FOR EVALUATING\n",
    "    while (env.terminal != True) and (env.days_step != (len(env.df_days) - 1)):\n",
    "        action = agent.compute_single_action(env.state)\n",
    "        env.step(action)\n",
    "        if (env.terminal == True) and (env.days_step != (len(env.df_days) - 1)):\n",
    "            env.reset()\n",
    "        elif (env.terminal == True) and (env.days_step == (len(env.df_days) - 1)):\n",
    "            #print(\"score = \", (env.money_spent_cumulative - env.money_spent_without_battery_cumulative)/np.abs(env.money_spent_without_battery_cumulative))\n",
    "            scores.append((env.money_spent_cumulative - env.money_spent_without_battery_cumulative)/np.abs(env.money_spent_without_battery_cumulative))\n",
    "            outside_capacity.append(np.sum(env.agent_outside_capacity_memory))\n",
    "            \n",
    "print(\"scores average = \", np.average(scores))\n",
    "print(\"outside capacity average = \", np.average(outside_capacity))\n",
    "print('------------')\n",
    "#Initialize env\n",
    "#While 'episode'\n",
    "#    action = agent(state)\n",
    "#    info = env.step(state)\n",
    "#\n",
    "#The rest info in inside 'env' class [score is there too]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZRIfPjxit9u",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "eTzt93eyc4tC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Battery_experiment\n"
     ]
    }
   ],
   "source": [
    "!ls ~/ray_results #/Battery_experiment/PG_BatteryEnvTrain-v0_70a76_00000_0_2022-04-30_11-55-33/checkpoint_007000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "FFQS9u0cc4tC"
   },
   "outputs": [],
   "source": [
    "!rm -rf ~/ray_results\n",
    "!mkdir ~/ray_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtarzz6Hc4tD",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zip -r ~/notebooks/Battery_experiment.zip ~/ray_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf6-OYbjjAIh"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ~/ray_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
